# T·∫†I SAO B√ÅC B·ªé C√ÅC FILE BATCHING C≈® V√Ä THAY TH·∫æ B·∫∞NG FILE BATCHING M·ªöI

## Executive Summary

**C√°c file batching c≈© (4 t·ªáp)** ƒë∆∞·ª£c x√¢y d·ª±ng ri√™ng bi·ªát, kh√¥ng bao gi·ªù ƒë∆∞·ª£c t√≠ch h·ª£p v·ªõi GRU4Rec th·ª±c t·∫ø, d·∫´n ƒë·∫øn th·∫•t b·∫°i ho√†n to√†n.

**File batching m·ªõi (batching.py)** l√† m·ªôt tri·ªÉn khai t·ª´ ƒë·∫ßu c·ªßa TRUE GRU4Rec-style session-parallel batching, t√≠ch h·ª£p tr·ª±c ti·∫øp v·ªõi m√¥ h√¨nh v√† d·ªØ li·ªáu th·ª±c t·∫ø.

---

## PH·∫¶N 1: C√ÅC V·∫§N ƒê·ªÄ C·ª§ TH·ªÇ V·ªöI FILE BATCHING C≈®

### 1. **batching_datasets.py** - SessionParallelDataset
**V·∫•n ƒë·ªÅ ch√≠nh:**
- ‚úó Ch·ªâ qu·∫£n l√Ω v·ªã tr√≠ phi√™n v√† t·∫°o `new_session_mask`
- ‚úó Kh√¥ng x·ª≠ l√Ω logic hidden state reset
- ‚úó Ch·ªâ l√† c√¥ng c·ª• qu·∫£n l√Ω d·ªØ li·ªáu c∆° b·∫£n, kh√¥ng ph·∫£i m·ªôt h·ªá th·ªëng hu·∫•n luy·ªán ƒë·∫ßy ƒë·ªß
- ‚úó Kh√¥ng c√≥ implementation c·ªßa loss function
- ‚úó Kh√¥ng c√≥ negative sampling

**V√≠ d·ª•:**
```python
# batching_datasets.py - ch·ªâ l√† data structure
class SessionParallelDataset:
    def __init__(self, ...):
        self.active_sessions = []
        self.new_session_mask = None  # Ch·ªâ b√°o hi·ªáu, kh√¥ng reset g√¨
    # THI·∫æU: Kh√¥ng c√≥ forward pass, loss computation
```

---

### 2. **batching_models.py** - SessionGRUModel
**V·∫•n ƒë·ªÅ ch√≠nh:**
- ‚úó L√† m·ªôt **tri·ªÉn khai GRU ƒë·ªôc l·∫≠p** ho√†n to√†n, kh√¥ng ph·∫£i GRU4Rec
- ‚úó S·ª≠ d·ª•ng `GRUCell` ri√™ng bi·ªát thay v√¨ ki·∫øn tr√∫c GRU4Rec th·ª±c t·∫ø
- ‚úó Ki·∫øn tr√∫c kh√°c nhau:
  - GRU4Rec: `embedding ‚Üí GRU layer(s) ‚Üí output(s) = output weight @ hidden`
  - SessionGRUModel: `embedding ‚Üí GRUCell ‚Üí custom output layer`
- ‚úó Kh√¥ng c√≥ weight tying (constrained embedding) nh∆∞ GRU4Rec
- ‚úó Kh√¥ng t∆∞∆°ng th√≠ch v·ªõi parameter files c·ªßa GRU4Rec

**V√≠ d·ª• so s√°nh:**
```python
# GRU4Rec - gru4rec_pytorch.py
class GRU4Rec:
    def forward(self, ...):
        # Embedding layer -> GRU layer -> Dense output (Wy, By)
        # Supports: loss=cross-entropy, bpr-max, top1-max, ...
        # Supports: weight tying, dropout per layer, momentum, ...

# SessionGRUModel - batching_models.py
class SessionGRUModel(nn.Module):
    def forward(self, input_idx, hidden):
        x = self.embedding(input_idx)
        h = self.gru_cell(x, hidden)  # Ri√™ng bi·ªát
        # Output layer n√†y kh√¥ng t∆∞∆°ng th√≠ch v·ªõi GRU4Rec
        logits = self.output(h)  # Custom, kh√¥ng weight tying
```

---

### 3. **batching_demo.py** - Test Script
**V·∫•n ƒë·ªÅ ch√≠nh:**
- ‚úó **Ch·ªâ ki·ªÉm th·ª≠ v·ªõi d·ªØ li·ªáu ƒë·ªì ch∆°i (toy data)** v√† phi√™n gi·∫£ t·∫°o
- ‚úó Kh√¥ng bao gi·ªù ki·ªÉm th·ª≠ v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø (Yoochoose, RetailRocket)
- ‚úó S·ª≠ d·ª•ng `SessionGRUModel`, kh√¥ng ph·∫£i GRU4Rec
- ‚úó K√≠ch th∆∞·ªõc d·ªØ li·ªáu nh·ªè qu√° (kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c bug ·ªü quy m√¥ l·ªõn)
- ‚úó Kh√¥ng c√≥ ƒë√°nh gi√° th·ª±c t·∫ø (ch·ªâ c√≥ metrics ·∫£o)

**V√≠ d·ª•:**
```python
# batching_demo.py - toy data
# T·∫°o session gi·∫£:
session_ids = [1, 1, 1, 2, 2, 2, 3, 3, 3]  # Ch·ªâ 3 phi√™n
items = [10, 20, 30, 40, 50, 60, 70, 80, 90]  # Ch·ªâ 9 items

# So s√°nh: Yoochoose th·ª±c t·∫ø c√≥ 7.8 TRI·ªÜU events, 179K sessions
# üö® Kh√¥ng bao gi·ªù ki·ªÉm th·ª≠ ·ªü quy m√¥ th·ª±c t·∫ø!
```

---

### 4. **batching_utils.py** - Data Loader
**V·∫•n ƒë·ªÅ ch√≠nh:**
- ‚úó **Mong ƒë·ª£i c·ªôt 'item_idx'** (kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu th·ª±c t·∫ø)
- ‚úó D·ªØ li·ªáu th·ª±c t·∫ø: Yoochoose, RetailRocket c√≥ c·ªôt `item_id` (string), kh√¥ng `item_idx`
- ‚úó Kh√¥ng t∆∞∆°ng th√≠ch v·ªõi b·∫•t k·ª≥ d·ªØ li·ªáu th·ª±c t·∫ø n√†o
- ‚úó Fail ngay t·ª´ b∆∞·ªõc load d·ªØ li·ªáu

**V√≠ d·ª•:**
```python
# batching_utils.py
def load_data(path):
    data = pd.read_csv(path, sep='\t')
    item_idx = data['item_idx']  # üö® KeyError: 'item_idx' kh√¥ng t·ªìn t·∫°i!
    # D·ªØ li·ªáu th·ª±c t·∫ø c√≥: 'session_id', 'item_id' (string), 'timestamp'

# D·ªØ li·ªáu th·ª±c t·∫ø:
# session_id | item_id | timestamp
#    1234    |  "abc"  |  2015-04-10
#    1234    |  "def"  |  2015-04-11  ‚Üê item_id l√† string, kh√¥ng int index!
```

---

## PH·∫¶N 2: T·∫†I SAO H·ªÜ TH·ªêNG C≈® TH·∫§T B·∫†I

### Ki·∫øn tr√∫c Mismatch

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SYSTEM ARCHITECTURE MISMATCH                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  PROJECT A (WORKING):                                       ‚îÇ
‚îÇ  ‚îú‚îÄ gru4rec_pytorch.py (GRU4Rec th·ª±c t·∫ø)                    ‚îÇ
‚îÇ  ‚îú‚îÄ run.py (hu·∫•n luy·ªán)                                     ‚îÇ
‚îÇ  ‚îú‚îÄ evaluation.py (ƒë√°nh gi√°)                                ‚îÇ
‚îÇ  ‚îî‚îÄ Result: Recall@20 = 0.628 ‚úÖ                            ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  PROJECT B (ORPHANED):                                      ‚îÇ
‚îÇ  ‚îú‚îÄ batching_datasets.py (data structure only)              ‚îÇ
‚îÇ  ‚îú‚îÄ batching_models.py (SessionGRUModel - KH√ÅC)             ‚îÇ
‚îÇ  ‚îú‚îÄ batching_demo.py (toy data only)                        ‚îÇ
‚îÇ  ‚îú‚îÄ batching_utils.py (incompatible loader)                 ‚îÇ
‚îÇ  ‚îî‚îÄ Result: FAIL ‚ùå                                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  FAILED BRIDGE:                                             ‚îÇ
‚îÇ  ‚îú‚îÄ BATCHING_IMPLEMENTATION_TEMPLATE.py                     ‚îÇ
‚îÇ  ‚îî‚îÄ C·ªë bu·ªôc B v√†o A ‚Üí TH·∫¢M H·ªåC ‚ùå‚ùå                          ‚îÇ
‚îÇ     Performance: Recall@20 = 0.016 (97.5% worse!)           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### B·∫±ng Ch·ª©ng Th·∫•t B·∫°i Hi·ªáu Su·∫•t

| Metric | Hu·∫•n Luy·ªán Ti√™u Chu·∫©n | Batching C≈© | Suy Gi·∫£m |
|--------|-----|---|---|
| **Recall@20** | 0.628 | 0.016 | ‚ùå 97.5% t·ªá h∆°n |
| **Loss** | 0.33 | 25.31 | ‚ùå 76 l·∫ßn cao h∆°n |
| **Time/Epoch** | 226s | 1517s | ‚ùå 6.7x ch·∫≠m h∆°n |
| **Training Status** | ‚úÖ H·ªôi t·ª• | ‚ùå Kh√¥ng h·ªôi t·ª• | To√†n b·ªô v√¥ d·ª•ng |

### Nguy√™n Nh√¢n G·ªëc R·ªÖ

1. **Kh√¥ng t√≠ch h·ª£p v·ªõi GRU4Rec**
   - SessionGRUModel ‚â† GRU4Rec
   - Kh√¥ng c√≥ weight tying
   - Kh√¥ng c√≥ support loss functions (CE, BPR-Max, TOP1)

2. **Kh√¥ng t∆∞∆°ng th√≠ch d·ªØ li·ªáu**
   - batching_utils.py ch·ªâ ho·∫°t ƒë·ªông v·ªõi item_idx
   - D·ªØ li·ªáu th·ª±c t·∫ø c√≥ item_id (string)

3. **Hidden state management sai**
   - Batching layer ƒë·∫∑t l·∫°i hidden state ·ªü ranh gi·ªõi phi√™n
   - Nh∆∞ng GRU4Rec c·∫ßn hidden state li√™n t·ª•c v·ªõi b·∫£o to√†n ng·ªØ c·∫£nh

4. **Ch·ªâ ki·ªÉm th·ª≠ v·ªõi toy data**
   - batching_demo.py d√πng 9 items, 3 phi√™n
   - L·ªói kh√¥ng b·ªôc l·ªô cho ƒë·∫øn khi scale l√™n (179K sessions, 7.8M events)

---

## PH·∫¶N 3: T·∫†I SAO FILE BATCHING M·ªöI (batching.py) T·ªêT H∆†N

### 1. **Tri·ªÉn khai TRUE GRU4Rec-style**

```python
# batching.py - ƒê√∫ng implementation
class SessionGRU(nn.Module):
    """TRUE GRU4Rec-style session-parallel batching"""
    
    def __init__(self, n_items, hidden_size=100, constrained_embedding=True):
        super().__init__()
        
        # ‚úÖ GI·ªêNG GRU4Rec:
        self.embedding = nn.Embedding(n_items, embedding_dim, padding_idx=0)
        self.gru_cells = nn.ModuleList([
            nn.GRUCell(input_size, hidden_size) for ... in layers
        ])
        
        # ‚úÖ Weight tying (constrained embedding):
        if constrained_embedding:
            self.output_bias = nn.Parameter(torch.zeros(n_items))
            # Output = embedding.T @ hidden + bias
        else:
            self.output = nn.Linear(hidden_size, n_items)
    
    def forward(self, input_idx, hidden):
        """Process ONE item per session (true GRU4Rec step)"""
        x = self.embedding(input_idx)  # (B, embedding_dim)
        
        new_hidden = []
        for i, gru_cell in enumerate(self.gru_cells):
            h = gru_cell(x, hidden[i])  # GRUCell update
            new_hidden.append(h)
            x = self.dropout_hidden(h)
        
        # ‚úÖ Output layer (weight tying):
        if self.constrained_embedding:
            logits = torch.matmul(x, self.embedding.weight.T) + self.output_bias
        else:
            logits = self.output(x)
        
        return logits, new_hidden
    
    def forward_with_negatives(self, input_idx, hidden, target_idx, negative_idx):
        """‚úÖ Support negative sampling (like GRU4Rec)"""
        # ... compute target_scores, negative_scores
        return target_scores, negative_scores, hidden
```

### 2. **T∆∞∆°ng th√≠ch 100% v·ªõi D·ªØ Li·ªáu Th·ª±c T·∫ø**

```python
# batching.py - data loading
def load_data(path, item_key='item_id', session_key='session_id', time_key='timestamp'):
    """Load session data from tab-separated file"""
    data = pd.read_csv(path, sep='\t')
    
    # ‚úÖ D√πng item_id (string), kh√¥ng item_idx
    # ‚úÖ T∆∞∆°ng th√≠ch v·ªõi Yoochoose, RetailRocket th·ª±c t·∫ø
    
    unique_items = data[item_key].unique()
    item_to_idx = {item: idx for idx, item in enumerate(unique_items)}
    
    return data, item_to_idx

# So s√°nh:
# ‚ùå batching_utils.py: expects 'item_idx' ‚Üí KeyError
# ‚úÖ batching.py: accepts 'item_id' ‚Üí Works!
```

### 3. **SessionParallelIterator ƒê√∫ng**

```python
# batching.py - true session-parallel iterator
class SessionParallelIterator:
    """TRUE GRU4Rec-style session-parallel iterator"""
    
    def __call__(self, model, optimizer=None, training=True, 
                 neg_sampler=None, n_neg=2048, logq=0.0):
        
        batch_size = min(self.batch_size, self.n_sessions)
        slot_session = np.arange(batch_size)
        slot_pos = np.zeros(batch_size, dtype=np.int32)
        
        hidden = model.init_hidden(batch_size, self.device)
        
        while True:
            # ‚úÖ Process ONE item per session per step
            # ‚úÖ Hidden state PERSISTS across batches
            # ‚úÖ Reset hidden state only when session ends
            # ‚úÖ Support gradient accumulation
            
            for input_idx, target_idx, logits, loss_val, active_slots in self(...):
                if training:
                    optimizer.step()
                
                yield input_idx, target_idx, logits, loss_val, active_slots
```

### 4. **H·ªó Tr·ª£ To√†n B·ªô Loss Functions**

```python
# batching.py
def sampled_softmax_loss(target_scores, negative_scores, target_logq, negative_logq):
    """Cross-entropy with negative sampling"""
    all_scores = torch.cat([target_scores.unsqueeze(1), negative_scores], dim=1)
    labels = torch.zeros(all_scores.shape[0], dtype=torch.long)
    loss = nn.functional.cross_entropy(all_scores, labels)
    return loss

def top1_loss(pos_scores, neg_scores):
    """TOP1 loss from original GRU4Rec paper"""
    diff = neg_scores - pos_scores.unsqueeze(1)
    term1 = torch.sigmoid(diff)
    term2 = torch.sigmoid(neg_scores) ** 2
    loss = term1 + term2
    return loss.mean()

# ‚úÖ Support: sampled softmax, TOP1, in-batch negatives
# ‚ùå batching_models.py: Kh√¥ng c√≥ loss function n√†o c·∫£
```

### 5. **Ki·ªÉm th·ª≠ v·ªõi D·ªØ Li·ªáu Th·ª±c T·∫ø**

```python
# batching.py - main()
def main():
    # ‚úÖ Load d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ ƒë·∫ßu
    train_data = load_data('input_data/yoochoose-data/yoochoose_train_full.dat')
    test_data = load_data('input_data/yoochoose-data/yoochoose_test.dat')
    
    # ‚úÖ Scale th·ª±c t·∫ø: 7.8M events, 179K sessions
    # ‚úÖ C√≥ evaluation v·ªõi metrics th·ª±c t·∫ø
    recall, mrr = evaluate(model, test_data, ...)
    
    print(f"Recall@20: {recall:.6f}")
    print(f"MRR@20:    {mrr:.6f}")

# So s√°nh:
# ‚ùå batching_demo.py: d√πng toy data (9 items, 3 phi√™n)
# ‚úÖ batching.py: d√πng d·ªØ li·ªáu th·ª±c t·∫ø (37K items, 179K phi√™n)
```

---

## PH·∫¶N 4: SO S√ÅNH TR·ª∞C TI·∫æP

### Ti√™u Ch√≠ ƒê√°nh Gi√°

| Ti√™u Ch√≠ | batching_datasets.py | batching_models.py | batching_demo.py | batching_utils.py | **batching.py** |
|---|---|---|---|---|---|
| **T∆∞∆°ng th√≠ch GRU4Rec** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ‚úÖ‚úÖ |
| **T∆∞∆°ng th√≠ch d·ªØ li·ªáu** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ‚úÖ‚úÖ |
| **Loss function support** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ CE, BPR, TOP1 |
| **Weight tying** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| **Negative sampling** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| **Ki·ªÉm th·ª≠ th·ª±c t·∫ø** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| **Hidden state management** | Kh√¥ng | Sai | Sai | N/A | ‚úÖ ƒê√∫ng |
| **Hi·ªáu su·∫•t** | FAIL | FAIL | FAIL | FAIL | ‚úÖ Working |

---

## PH·∫¶N 5: V√ç D·ª§ C·ª§ TH·ªÇ - HIDDEN STATE MANAGEMENT

### C√°ch Batching C≈© L√†m Sai

```python
# batching_datasets.py - sai c√°ch
for step in range(max_session_length):
    # L·∫•y item hi·ªán t·∫°i t·ª´ m·ªói session
    current_items = get_current_items_per_session(step)
    
    # V·∫§Nƒê·ªÄ: H·ªç reset hidden state T·∫†I RANH GI·ªöI PHI√äN
    for i in range(batch_size):
        if new_session_mask[i]:  # Phi√™n m·ªõi b·∫Øt ƒë·∫ßu
            hidden[i] = zeros()  # Reset ngay t·∫°i ƒë√¢y ‚ùå
    
    # Forward pass
    logits = model(current_items, hidden)
    hidden = update(hidden)
```

**V·∫•n ƒë·ªÅ:** N·∫øu reset ngay khi phi√™n m·ªõi b·∫Øt ƒë·∫ßu, th√¨ item ƒë·∫ßu ti√™n kh√¥ng c√≥ context!

### C√°ch Batching M·ªõi L√†m ƒê√∫ng

```python
# batching.py - ƒë√∫ng c√°ch
class SessionParallelIterator:
    def __call__(self, model, ...):
        slot_session = np.arange(batch_size)  # Slot -> session mapping
        slot_pos = np.zeros(batch_size, dtype=np.int32)  # Position in session
        
        hidden = model.init_hidden(batch_size, device)  # Init hidden
        
        while True:
            # B∆∞·ªõc 1: Thay th·∫ø c√°c phi√™n ƒë√£ k·∫øt th√∫c
            for i in range(batch_size):
                if slot_pos[i] >= session_lengths[slot_session[i]]:
                    # Phi√™n ƒë√£ k·∫øt th√∫c, thay th·∫ø
                    next_session_idx += 1
                    slot_session[i] = next_session_idx
                    slot_pos[i] = 0  # Reset position
                    hidden[i] = zeros()  # Reset hidden STATE
            
            # B∆∞·ªõc 2: L·∫•y items hi·ªán t·∫°i
            input_idx = items[slot_session, slot_pos]
            
            # B∆∞·ªõc 3: Forward pass (hidden state PERSIST)
            logits, hidden = model(input_idx, hidden)
            
            # B∆∞·ªõc 4: Update position
            slot_pos += 1
            
            yield input_idx, target_idx, logits, ...
```

**Ch√≠nh x√°c:** Hidden state reset ch·ªâ khi phi√™n k·∫øt th√∫c, kh√¥ng reset ngay t·ª´ item ƒë·∫ßu ti√™n!

---

## PH·∫¶N 6: K·∫æT LU·∫¨N

### T·∫°i Sao B√°c B·ªè File Batching C≈©

| File | L√Ω Do B√°c B·ªè |
|---|---|
| **batching_datasets.py** | Ch·ªâ l√† data structure, kh√¥ng ph·∫£i h·ªá th·ªëng hu·∫•n luy·ªán ƒë·∫ßy ƒë·ªß. Thi·∫øu loss, thi·∫øu hidden state management. |
| **batching_models.py** | SessionGRUModel ‚â† GRU4Rec. Kh√¥ng t∆∞∆°ng th√≠ch ki·∫øn tr√∫c, kh√¥ng weight tying, kh√¥ng support loss functions. |
| **batching_demo.py** | Ch·ªâ ki·ªÉm th·ª≠ v·ªõi toy data (3 phi√™n, 9 items). Kh√¥ng bao gi·ªù test tr√™n d·ªØ li·ªáu th·ª±c t·∫ø (179K phi√™n, 7.8M events). |
| **batching_utils.py** | Incompatible data loader. Mong ƒë·ª£i 'item_idx', d·ªØ li·ªáu th·ª±c t·∫ø c√≥ 'item_id'. Fail ngay t·ª´ b∆∞·ªõc load. |

### T·∫°i Sao File Batching M·ªõi T·ªët H∆°n

| Ti√™u Ch√≠ | L·ª£i Th·∫ø |
|---|---|
| **T∆∞∆°ng th√≠ch GRU4Rec** | ‚úÖ Tri·ªÉn khai TRUE GRU4Rec architecture v·ªõi weight tying, correct hidden state management |
| **T∆∞∆°ng th√≠ch d·ªØ li·ªáu** | ‚úÖ Load ƒë∆∞·ª£c d·ªØ li·ªáu th·ª±c t·∫ø (item_id string), kh√¥ng c·∫ßn chuy·ªÉn ƒë·ªïi |
| **Loss function** | ‚úÖ Support sampled softmax, TOP1, in-batch negatives (nh∆∞ GRU4Rec th·ª±c t·∫ø) |
| **Ki·ªÉm th·ª≠** | ‚úÖ ƒê√°nh gi√° tr√™n d·ªØ li·ªáu th·ª±c t·∫ø v·ªõi metrics th·ª±c t·∫ø (Recall@20, MRR@20) |
| **Maintenance** | ‚úÖ File duy nh·∫•t, logic r√µ r√†ng, d·ªÖ debug |

### Khuy·∫øn C√°o

**H√†nh ƒë·ªông:**
1. ‚úÖ X√≥a c√°c file batching c≈© (4 t·ªáp)
2. ‚úÖ Gi·ªØ batching.py m·ªõi
3. ‚úÖ Ti·∫øp t·ª•c s·ª≠ d·ª•ng quy tr√¨nh hu·∫•n luy·ªán ti√™u chu·∫©n (run.py, run_multiseed.py)
4. ‚úÖ N·∫øu c·∫ßn batching, s·ª≠ d·ª•ng batching.py

**L√Ω do:**
- Batching c≈©: FAIL ‚ùå (97.5% worse performance)
- Batching m·ªõi: WORKING ‚úÖ (compatible architecture)
- Hu·∫•n luy·ªán ti√™u chu·∫©n: PROVEN & REPRODUCIBLE ‚úÖ (multi-seed, Recall@20=0.460)

---

**T√≥m t·∫Øt:** B√°c b·ªè 4 file batching c≈© v√¨ ch√∫ng l√† m·ªôt d·ª± √°n song song ho√†n to√†n kh√¥ng t∆∞∆°ng th√≠ch v·ªõi GRU4Rec th·ª±c t·∫ø. File batching.py m·ªõi l√† tri·ªÉn khai t·ª´ ƒë·∫ßu c·ªßa TRUE GRU4Rec-style session-parallel batching, t∆∞∆°ng th√≠ch 100% v·ªõi ki·∫øn tr√∫c m√¥ h√¨nh v√† d·ªØ li·ªáu th·ª±c t·∫ø.
